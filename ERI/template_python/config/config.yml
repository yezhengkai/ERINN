# - Use FW2_5D to generate dataset for training/validation/testing
# -- generic setting
dataset_dir: "../data/raw_data"  # In this directory, the program will automatically create the train / valid / test directory.
num_samples: 50000  # number of samples. That is, the total number of synthetic models that will be generated in one round.
train_ratio: 0.8  # Ratio of the number of samples (num_samples) to be used for training.
valid_ratio: 0.1  # Ratio of the number of samples (num_samples) to be used for validating.
test_ratio: 0.1  # Ratio of the number of samples (num_samples) to be used for testing.
geometry_urf: "../config/geo.urf"  # The path to the urf file is used to construct the electrode array in forward simulation.
fw2_5D_para_pkl: "../config/fw2_5D_para.pkl"  # The path to the pickle file is used to read and write the necessary parameters used in FW2_5D.
glob_para_pkl: "../config/glob_para.pkl"  # Information about the forward model.
array_type: "all_combination"  # {"all_combination", "Wenner"}. Select the electrode pair that matches the array configuration. All array types are dipole-dipole settings.
num_k_g: 4  # control the number of wave number (k) and weight (g).

# -- Generate synthetic models randomly. (NOTE: we will use truncated normal in linear scale)
# --- generic setting
nx: 140  # number of mesh in the x direction
nz: 30  # number of mesh in the z direction
# ---- This kernel is used to smooth (moving average) synthetic resistivity models in linear scale.
x_kernel_size: 3  # Kernel size in the x direction.
z_kernel_size: 3  # Kernel size in the z direction.

# --- background
scale_background: "linear"  # {"linear", "log10"}. The resistivity scale during the sampling phase.
pdf_background: "normal"  # {"uniform", "normal"}. The probability distribution function of the sample.
a_background: 10  # lower bound or mu (mean) of pdf_background
b_background: 1  # upper bound or std (standard deviation) of pdf_background
# ---- Use following parameters to simulate porous media (Each mesh has a different value).
use_hidden_background: True  # {True, False}. If True, it will use `hidden_*` to control a_background and b_background.
hidden_pdf_background: "uniform"  # {"uniform", "normal"}. The hidden probability distribution function of the a_background and b_background.
hidden_a_for_a_background: 0.001  # lower bound or mu (mean) of hidden_pdf_background for hidden variable a_background
hidden_b_for_a_background: 1000  # upper bound or std(standard deviation) of hidden_pdf_background for hidden variable a_background
hidden_a_for_b_background: 0.001  # lower bound or mu (mean) of hidden_pdf_background for hidden variable b_background
hidden_b_for_b_background: 100  # upper bound or std(standard deviation) for hidden variable b_background

# --- rectangle (block)
num_rect:  # number of rectangles
  type: "list"  # {"list", "range"}. The interval of type "range" including start but excluding stop.
  value: [1]  # random sampling in `value` defined by `type`
# ---- geometry
w_range: [1, 140]  # width range (x direction)
h_range: [1, 30]  # height range (z direction)
# ---- value
scale_rect: "linear"  # {"linear", "log10"}. The resistivity scale during the sampling phase.
pdf_rect: "normal"  # {"uniform", "normal"}. The probability distribution function of the sample.
a_rect: 1000  # lower bound or mu (mean) of pdf_background
b_rect: 2000  # upper bound or std (standard deviation) of pdf_background
# ----- Use following parameters to simulate porous media (Each mesh has a different value).
use_hidden_rect: True  # {True, False}. If True, it will use `hidden_*` to control a_rect and b_rect.
hidden_pdf_rect: "uniform"  # {"uniform", "normal"}. The hidden probability distribution function of the a_rect and b_rect.
hidden_a_for_a_rect: 0.001  # lower bound or mu (mean) of hidden_pdf_background for hidden variable a_rect
hidden_b_for_a_rect: 1000  # upper bound or std(standard deviation) of hidden_pdf_background for hidden variable a_rect
hidden_a_for_b_rect: 0.001  # lower bound or mu (mean) of hidden_pdf_background for hidden variable b_rect
hidden_b_for_b_rect: 100  # upper bound or std(standard deviation) for hidden variable b_rect

# --- circle
num_circle:  # number of circles
  type: "list"  # {"list", "range"}. The interval of type "range" including start but excluding stop.
  value: [0]  # random sampling in `value` defined by `type`
# ---- geometry
radius_bound: [5, 20]  # lower bound and upper bound of radius
# ---- value
scale_circle: "linear"  # {"linear", "log10"}. The resistivity scale during the sampling phase.
pdf_circle: "normal"  # {"uniform", "normal"}. The probability distribution function of the sample.
a_circle: 2  # lower bound or mu (mean) of pdf_background
b_circle: 2.5  # upper bound or std (standard deviation) of pdf_background
# ----- Use following parameters to simulate porous media (Each mesh has a different value).
use_hidden_circle: True  # {True, False}. If True, it will use `hidden_*` to control a_circle and b_circle.
hidden_pdf_circle: "uniform"  # {"uniform", "normal"}. The hidden probability distribution function of the a_circle and b_circle.
hidden_a_for_a_circle: 2900  # lower bound or mu (mean) of hidden_pdf_background for hidden variable a_circle
hidden_b_for_a_circle: 3100  # upper bound or std(standard deviation) of hidden_pdf_background for hidden variable a_circle
hidden_a_for_b_circle: 9  # lower bound or mu (mean) of hidden_pdf_background for hidden variable b_circle
hidden_b_for_b_circle: 11  # upper bound or std(standard deviation) for hidden variable b_circle


# ======================================================================================================================
# - Preprocess raw data and save as processed data.
raw_data_dir: "../data/raw_data"  # Walk through this directory (contain subdirectory) to read raw data (pickle file).
processed_data_dir: "../data/noise_10"  # Processed dataset is saved in this directory. (subdirectories will be created automatically)
preprocess:  # Add_noise is implemented earlier than log_transform
  add_noise:
    perform: True  # {True, False}. Whether to perform add_noise.
    kwargs:
      ratio: 0.1  # Noise added to element is proportional to this value.
  log_transform:  # You can also perform log transform in data generator.
    perform: False  # {True, False}. Whether to perform log_transform.
    kwargs:
      inverse: False  # {True, False}. Whether to perform an inverse transformation.
      inplace: True  # {True, False}. Whether to use inplace mode.
  to_midpoint:  # Reshape inputs tensor to midpoint image. shape = (accumulated number of same midpoint, number of midpoint, 1)
    perform: False  # {True, False}. Whether to perform to_midpoint. *NOTE: Don't use `to_midpoint` and `to_txrx` at the same time*
  to_txrx:  # Reshape inputs tensor to Tx-Rx image. shape = (number of Tx pair, number of Rx pair, 1)
    perform: False  # {True, False}. Whether to perform to_TxRx. *NOTE: Don't use `to_midpoint` and `to_txrx` at the same time*


# ======================================================================================================================
# - Training/Inferring
# -- custom neural network
custom_NN: "<module 'my_model' from '../config/model.py'>"  # custom keras model
# -- directory
train_dir: "../data/noise_10/train"  # training dataset
valid_dir: "../data/noise_10/valid"  # validation dataset
model_dir: "../models/add_noise_log_transform"  # In this directory, the program will automatically create the logs/predictions/weights directory.
pre_trained_weights: ""  # hdf5 file saved the weight of the keras model. If you don't want to use pre-trained weights, use an empty string.
# -- preprocess in data generator. *NOTE: Some operations are data augmentation.*
preprocess_generator:  # Add_noise is implemented earlier than log_transform
  add_noise:  # Because we add random noise every time, this operation is data augmentation.
    perform: False  # {True, False}. Whether to perform add_noise.
    kwargs:
      ratio: 0.1  # Noise added to element is proportional to this value.
  log_transform:
    perform: True  # {True, False}. Whether to perform log_transform.
    kwargs:
      inverse: False  # {True, False}. Whether to perform an inverse transformation.
      inplace: True  # {True, False}. Whether to use inplace mode.
  to_midpoint:  # Reshape inputs tensor to midpoint image. shape = (accumulated number of same midpoint, number of midpoint, 1)
    perform: False  # {True, False}. Whether to perform to_midpoint. *NOTE: Don't use `to_midpoint` and `to_txrx` at the same time*
  to_txrx:  # Reshape inputs tensor to Tx-Rx image. shape = (number of Tx pair, number of Rx pair, 1)
    perform: False  # {True, False}. Whether to perform to_TxRx. *NOTE: Don't use `to_midpoint` and `to_txrx` at the same time*
# -- hyper parameters
num_gpu: 2  # number of gpu
batch_size: 64  # Size for mini-batch gradient descent
num_epochs: 250  # number of epochs
optimizer:
  class_name: "Adam"  # Select the optimizer defined in tf.keras
  config:  # You can add parameters that correspond to a specific optimizer.
    learning_rate: 1e-4
    beta_1: 0.9
    beta_2: 0.999
    epsilon: 1e-07
    amsgrad: False
    clipnorm: 1
    clipvalue: 0.5
loss: "mean_squared_error"  # Select the loss function in tf.keras.
